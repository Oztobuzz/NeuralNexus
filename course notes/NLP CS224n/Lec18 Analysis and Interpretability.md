---
id: Lec18
created_date: 2024-09-12
updated_date: 2024-09-12
type: course
---
# ğŸ“š Lec18 Analysis and Interpretability
- **ğŸ·ï¸Tags** :   #09-2024 #course #NLP #pending #lecture 
## ğŸ“ Notes
- 

## â“ Questions
- 

## ğŸ‘‹ New terms 

Out-of-domain evaluation: Evaluating a model on data that differs in distribution or characteristics from the data it was trained on.**Minimal pairs**Pairs of sentences differing in a single linguistic feature, used to test a model's sensitivity to that feature.**Saliency map**A visualization highlighting the importance of each input feature to a model's prediction.**Input reduction**Simplifying the input while preserving the model's prediction to identify the minimal information required.**Adversarial example**A carefully crafted input designed to fool a model into making a wrong prediction.**Probing**Training a separate classifier on a frozen neural network's representations to assess the accessibility of specific features.**Attention head**A component of a Transformer model that learns to attend to different parts of the input sequence.**Emergent simplicity**The observation that complex neural networks often exhibit surprisingly interpretable patterns in their internal representations.**Model ablation**Removing or simplifying parts of a model to analyze their contribution to its performance.**Linguistic probing**Using probing techniques to analyze the linguistic knowledge encoded in a neural network's representations.

## ğŸ”— Related links
- Questions ask by user: [[Analysis and Interpretibility note]] 
- Other resources:  
- 

